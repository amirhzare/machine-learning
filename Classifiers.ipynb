{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# some popular classifiers in python\n","# the features extracted from corel5k images by InceptionResnet v2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87898,"status":"ok","timestamp":1712137726075,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"_pQ4qLiqE_0_","outputId":"3e489a60-cb2e-4864-9070-7b43525228a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["# from google.colab import drive\n","# # drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10206,"status":"ok","timestamp":1712137787432,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"CEUQb__9XSQ7","outputId":"9b2b4944-a398-4b89-d3c9-6a67486b5742"},"outputs":[],"source":["# !pip install mrmr_selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install imbalanced-learn"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1135,"status":"ok","timestamp":1712140466279,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"vHULtGQIXKpW"},"outputs":[],"source":["import pandas as pd\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n","import tensorflow as tf\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from mrmr import mrmr_classif\n","from sklearn.model_selection import train_test_split\n","from scipy.io import savemat, loadmat\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["data = loadmat('Corel5K.mat')['features'].reshape(5000, 1536)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(data)\n","df['class'] = (df.index // 100) + 1"]},{"cell_type":"markdown","metadata":{},"source":["## Train & Test split"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Split into training and testing sets (80% training, 20% testing)\n","train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=42)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# train_df['class'].value_counts()\n","# test_df['class'].value_counts()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["xtrain = train_df.iloc[:,:-1].to_numpy()\n","ytrain = train_df.iloc[:,-1].to_numpy()\n","xtest  = test_df.iloc[:,:-1].to_numpy()\n","ytest  = test_df.iloc[:,-1].to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyIzlSx9pbwV"},"outputs":[],"source":["# mrmr feature selection\n","# xtrain_df = pd.DataFrame(xtrain)\n","# ytrain_df = pd.DataFrame(ytrain)\n","\n","# selected_features = mrmr_classif(X=xtrain_df, y=ytrain_df, K=1500)\n","# x_train_selected = xtrain[:,selected_features]\n","# x_test_selected  = xtest[:,selected_features]"]},{"cell_type":"markdown","metadata":{"id":"KUXy_rP6mdiv"},"source":["## Preprocess : min-max , l1 , l2  normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJAR7GZhqIbJ"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler , Normalizer\n","\n","x = df.drop('Classification', axis=1)\n","y = df['Classification']\n","\n","scalar = MinMaxScaler()\n","# scalar = Normalizer(norm=\"l1\")\n","x_norm = scalar.fit_transform(x)"]},{"cell_type":"markdown","metadata":{"id":"NObgNXiamJmT"},"source":["## Feature selection : SelectKBest"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wokag5rfmdB9","outputId":"94028091-3647-40ae-d708-bf273ac95456"},"outputs":[],"source":["# selector = SelectKBest(score_func=f_classif, k=7)\n","# x_train_selected = selector.fit_transform(x_train, y_train)\n","\n","# x_test_selected = selector.transform(x_test)\n","\n","# print(x_train_selected.shape)\n","# print(x_test_selected.shape)"]},{"cell_type":"markdown","metadata":{"id":"RqqkhQmYvt-U"},"source":["# Classifying : Logitic Regression"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41983,"status":"ok","timestamp":1712140852934,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"b8hIRNSAvyEB","outputId":"4bc38e20-d254-47b6-ac41-15eaf2bfed76"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 95.7\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       1.00      0.95      0.97        20\n","           2       1.00      0.95      0.97        20\n","           3       0.95      1.00      0.98        20\n","           4       0.95      1.00      0.98        20\n","           5       1.00      1.00      1.00        20\n","           6       1.00      0.95      0.97        20\n","           7       0.90      0.95      0.93        20\n","           8       0.95      1.00      0.98        20\n","           9       0.91      1.00      0.95        20\n","          10       0.74      0.85      0.79        20\n","          11       0.95      0.95      0.95        20\n","          12       1.00      0.90      0.95        20\n","          13       0.90      0.95      0.93        20\n","          14       0.83      0.95      0.88        20\n","          15       1.00      0.95      0.97        20\n","          16       0.95      1.00      0.98        20\n","          17       1.00      0.95      0.97        20\n","          18       1.00      0.95      0.97        20\n","          19       1.00      1.00      1.00        20\n","          20       1.00      0.80      0.89        20\n","          21       1.00      1.00      1.00        20\n","          22       0.93      0.70      0.80        20\n","          23       1.00      1.00      1.00        20\n","          24       1.00      0.90      0.95        20\n","          25       0.87      1.00      0.93        20\n","          26       0.95      0.90      0.92        20\n","          27       1.00      0.95      0.97        20\n","          28       1.00      1.00      1.00        20\n","          29       0.95      0.95      0.95        20\n","          30       0.87      1.00      0.93        20\n","          31       1.00      0.95      0.97        20\n","          32       0.91      1.00      0.95        20\n","          33       0.90      0.95      0.93        20\n","          34       1.00      0.95      0.97        20\n","          35       0.95      0.95      0.95        20\n","          36       1.00      0.95      0.97        20\n","          37       1.00      0.80      0.89        20\n","          38       0.95      1.00      0.98        20\n","          39       0.91      1.00      0.95        20\n","          40       0.95      0.95      0.95        20\n","          41       1.00      1.00      1.00        20\n","          42       0.91      1.00      0.95        20\n","          43       0.95      0.90      0.92        20\n","          44       0.95      1.00      0.98        20\n","          45       1.00      1.00      1.00        20\n","          46       1.00      1.00      1.00        20\n","          47       1.00      1.00      1.00        20\n","          48       1.00      1.00      1.00        20\n","          49       1.00      1.00      1.00        20\n","          50       1.00      1.00      1.00        20\n","\n","    accuracy                           0.96      1000\n","   macro avg       0.96      0.96      0.96      1000\n","weighted avg       0.96      0.96      0.96      1000\n","\n","[[19  0  0 ...  0  0  0]\n"," [ 0 19  0 ...  0  0  0]\n"," [ 0  0 20 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 20  0  0]\n"," [ 0  0  0 ...  0 20  0]\n"," [ 0  0  0 ...  0  0 20]]\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","clf = LogisticRegression()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"Y6nNUQNRxrfZ"},"source":["Classifying : SVM"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267202,"status":"ok","timestamp":1712141579744,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"VNvfzlG3xhfm","outputId":"38c7c388-9ae8-4247-fadd-8e6aea85df2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 91.9\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.94      0.85      0.89        20\n","           2       1.00      0.95      0.97        20\n","           3       1.00      1.00      1.00        20\n","           4       0.95      0.95      0.95        20\n","           5       1.00      1.00      1.00        20\n","           6       1.00      0.95      0.97        20\n","           7       0.86      0.95      0.90        20\n","           8       0.95      1.00      0.98        20\n","           9       0.86      0.95      0.90        20\n","          10       0.75      0.60      0.67        20\n","          11       0.89      0.85      0.87        20\n","          12       0.56      0.95      0.70        20\n","          13       0.80      1.00      0.89        20\n","          14       0.77      0.85      0.81        20\n","          15       0.95      0.95      0.95        20\n","          16       0.95      1.00      0.98        20\n","          17       0.91      1.00      0.95        20\n","          18       1.00      0.90      0.95        20\n","          19       1.00      1.00      1.00        20\n","          20       0.93      0.70      0.80        20\n","          21       1.00      0.95      0.97        20\n","          22       0.88      0.70      0.78        20\n","          23       1.00      0.90      0.95        20\n","          24       0.95      1.00      0.98        20\n","          25       0.77      1.00      0.87        20\n","          26       0.94      0.80      0.86        20\n","          27       0.95      0.95      0.95        20\n","          28       1.00      1.00      1.00        20\n","          29       0.95      0.95      0.95        20\n","          30       0.89      0.85      0.87        20\n","          31       0.94      0.80      0.86        20\n","          32       0.90      0.95      0.93        20\n","          33       0.89      0.85      0.87        20\n","          34       1.00      1.00      1.00        20\n","          35       0.95      0.95      0.95        20\n","          36       0.90      0.90      0.90        20\n","          37       1.00      0.60      0.75        20\n","          38       0.95      1.00      0.98        20\n","          39       0.86      0.95      0.90        20\n","          40       0.95      0.95      0.95        20\n","          41       1.00      1.00      1.00        20\n","          42       1.00      0.95      0.97        20\n","          43       0.94      0.85      0.89        20\n","          44       0.83      0.95      0.88        20\n","          45       0.95      0.90      0.92        20\n","          46       0.95      0.95      0.95        20\n","          47       1.00      1.00      1.00        20\n","          48       1.00      1.00      1.00        20\n","          49       0.95      1.00      0.98        20\n","          50       0.95      0.90      0.92        20\n","\n","    accuracy                           0.92      1000\n","   macro avg       0.93      0.92      0.92      1000\n","weighted avg       0.93      0.92      0.92      1000\n","\n","[[17  0  0 ...  0  0  0]\n"," [ 0 19  0 ...  0  0  0]\n"," [ 0  0 20 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 20  0  0]\n"," [ 0  0  0 ...  0 20  0]\n"," [ 1  0  0 ...  0  0 18]]\n"]}],"source":["from sklearn import svm\n","# {'rbf', 'linear', 'poly', 'sigmoid', 'precomputed'}\n","clf = svm.SVC(kernel='poly')\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"lRHIjAI_M0TY"},"source":["## Classifying : RandomForest"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205263,"status":"ok","timestamp":1712141927856,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"MLNKMGZ7M4CO","outputId":"0f04a876-b635-4526-891c-d91ac0d12c3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 91.4\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.89      0.80      0.84        20\n","           2       1.00      0.95      0.97        20\n","           3       0.95      1.00      0.98        20\n","           4       0.95      1.00      0.98        20\n","           5       1.00      1.00      1.00        20\n","           6       1.00      0.95      0.97        20\n","           7       0.82      0.90      0.86        20\n","           8       0.91      1.00      0.95        20\n","           9       0.90      0.90      0.90        20\n","          10       0.82      0.45      0.58        20\n","          11       0.95      0.95      0.95        20\n","          12       0.82      0.90      0.86        20\n","          13       0.86      0.95      0.90        20\n","          14       0.83      0.95      0.88        20\n","          15       1.00      0.95      0.97        20\n","          16       0.91      1.00      0.95        20\n","          17       0.95      0.95      0.95        20\n","          18       1.00      0.90      0.95        20\n","          19       0.95      1.00      0.98        20\n","          20       0.87      0.65      0.74        20\n","          21       1.00      0.95      0.97        20\n","          22       0.94      0.80      0.86        20\n","          23       1.00      0.95      0.97        20\n","          24       0.95      0.95      0.95        20\n","          25       0.80      1.00      0.89        20\n","          26       0.86      0.90      0.88        20\n","          27       1.00      0.85      0.92        20\n","          28       1.00      0.95      0.97        20\n","          29       0.95      0.90      0.92        20\n","          30       0.86      0.90      0.88        20\n","          31       0.90      0.95      0.93        20\n","          32       0.90      0.90      0.90        20\n","          33       0.70      0.80      0.74        20\n","          34       0.95      0.95      0.95        20\n","          35       0.95      0.95      0.95        20\n","          36       0.86      0.90      0.88        20\n","          37       1.00      0.70      0.82        20\n","          38       0.91      1.00      0.95        20\n","          39       0.73      0.95      0.83        20\n","          40       0.95      0.90      0.92        20\n","          41       1.00      1.00      1.00        20\n","          42       1.00      0.90      0.95        20\n","          43       0.89      0.85      0.87        20\n","          44       0.78      0.90      0.84        20\n","          45       0.82      0.90      0.86        20\n","          46       0.95      1.00      0.98        20\n","          47       1.00      0.95      0.97        20\n","          48       1.00      1.00      1.00        20\n","          49       1.00      1.00      1.00        20\n","          50       0.90      0.90      0.90        20\n","\n","    accuracy                           0.91      1000\n","   macro avg       0.92      0.91      0.91      1000\n","weighted avg       0.92      0.91      0.91      1000\n","\n","[[16  0  0 ...  0  0  0]\n"," [ 0 19  0 ...  0  0  0]\n"," [ 0  0 20 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 20  0  0]\n"," [ 0  0  0 ...  0 20  0]\n"," [ 2  0  0 ...  0  0 18]]\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf = RandomForestClassifier()\n","clf.fit(xtrain, ytrain)\n","\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"_rP1ma6QVA6B"},"source":["## Classifying : GaussianNavieBayes"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1578,"status":"ok","timestamp":1712141948750,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"jYqmVcy2VKaC","outputId":"1f9182cb-41b6-4ebe-b3d9-ada24999ec85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 87.6\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       1.00      0.80      0.89        20\n","           2       1.00      0.95      0.97        20\n","           3       1.00      0.95      0.97        20\n","           4       1.00      0.80      0.89        20\n","           5       1.00      1.00      1.00        20\n","           6       1.00      0.90      0.95        20\n","           7       0.79      0.75      0.77        20\n","           8       0.95      0.95      0.95        20\n","           9       0.94      0.85      0.89        20\n","          10       0.54      0.70      0.61        20\n","          11       0.86      0.90      0.88        20\n","          12       0.78      0.90      0.84        20\n","          13       0.85      0.85      0.85        20\n","          14       0.90      0.90      0.90        20\n","          15       1.00      0.85      0.92        20\n","          16       0.89      0.80      0.84        20\n","          17       0.41      1.00      0.58        20\n","          18       1.00      0.90      0.95        20\n","          19       1.00      0.95      0.97        20\n","          20       0.83      0.75      0.79        20\n","          21       1.00      0.95      0.97        20\n","          22       0.92      0.60      0.73        20\n","          23       1.00      0.80      0.89        20\n","          24       0.90      0.95      0.93        20\n","          25       0.90      0.95      0.93        20\n","          26       0.82      0.90      0.86        20\n","          27       1.00      0.85      0.92        20\n","          28       1.00      0.95      0.97        20\n","          29       0.94      0.85      0.89        20\n","          30       0.84      0.80      0.82        20\n","          31       0.68      0.75      0.71        20\n","          32       0.90      0.90      0.90        20\n","          33       0.72      0.90      0.80        20\n","          34       1.00      0.90      0.95        20\n","          35       0.89      0.80      0.84        20\n","          36       0.89      0.85      0.87        20\n","          37       0.80      0.60      0.69        20\n","          38       0.95      1.00      0.98        20\n","          39       0.83      1.00      0.91        20\n","          40       1.00      0.90      0.95        20\n","          41       1.00      0.90      0.95        20\n","          42       1.00      0.90      0.95        20\n","          43       0.94      0.80      0.86        20\n","          44       0.68      0.85      0.76        20\n","          45       1.00      0.80      0.89        20\n","          46       0.87      1.00      0.93        20\n","          47       1.00      0.95      0.97        20\n","          48       1.00      1.00      1.00        20\n","          49       0.95      0.95      0.95        20\n","          50       0.80      1.00      0.89        20\n","\n","    accuracy                           0.88      1000\n","   macro avg       0.90      0.88      0.88      1000\n","weighted avg       0.90      0.88      0.88      1000\n","\n","[[16  0  0 ...  0  0  0]\n"," [ 0 19  0 ...  0  0  0]\n"," [ 0  0 19 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 20  0  0]\n"," [ 0  0  0 ...  0 19  0]\n"," [ 0  0  0 ...  0  0 20]]\n"]}],"source":["from sklearn.naive_bayes import GaussianNB\n","\n","clf = GaussianNB()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"mn6L6uakaPs8"},"source":["## Classifying : KNearestNeighbours"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9968,"status":"ok","timestamp":1712141964250,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"5-w9aKQzaXeh","outputId":"6f308ae0-edf3-4371-9da7-72cbb13ed3ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 91.4\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.75      0.90      0.82        20\n","           2       1.00      0.95      0.97        20\n","           3       0.95      1.00      0.98        20\n","           4       0.91      1.00      0.95        20\n","           5       1.00      1.00      1.00        20\n","           6       1.00      0.95      0.97        20\n","           7       0.79      0.95      0.86        20\n","           8       0.91      1.00      0.95        20\n","           9       0.86      0.90      0.88        20\n","          10       0.70      0.80      0.74        20\n","          11       0.88      0.75      0.81        20\n","          12       1.00      0.90      0.95        20\n","          13       0.69      0.90      0.78        20\n","          14       0.86      0.90      0.88        20\n","          15       1.00      0.90      0.95        20\n","          16       0.89      0.85      0.87        20\n","          17       1.00      0.95      0.97        20\n","          18       0.94      0.85      0.89        20\n","          19       0.95      1.00      0.98        20\n","          20       0.89      0.85      0.87        20\n","          21       0.87      1.00      0.93        20\n","          22       0.89      0.85      0.87        20\n","          23       0.95      1.00      0.98        20\n","          24       1.00      0.90      0.95        20\n","          25       0.91      1.00      0.95        20\n","          26       0.89      0.85      0.87        20\n","          27       1.00      0.95      0.97        20\n","          28       0.95      1.00      0.98        20\n","          29       0.95      0.95      0.95        20\n","          30       0.81      0.85      0.83        20\n","          31       1.00      0.65      0.79        20\n","          32       0.90      0.95      0.93        20\n","          33       0.84      0.80      0.82        20\n","          34       1.00      1.00      1.00        20\n","          35       0.89      0.85      0.87        20\n","          36       0.95      0.90      0.92        20\n","          37       0.85      0.55      0.67        20\n","          38       0.95      0.95      0.95        20\n","          39       0.86      0.90      0.88        20\n","          40       1.00      0.95      0.97        20\n","          41       1.00      1.00      1.00        20\n","          42       1.00      0.90      0.95        20\n","          43       0.90      0.90      0.90        20\n","          44       0.75      0.90      0.82        20\n","          45       0.95      0.95      0.95        20\n","          46       0.95      1.00      0.98        20\n","          47       1.00      1.00      1.00        20\n","          48       1.00      1.00      1.00        20\n","          49       0.95      1.00      0.98        20\n","          50       1.00      0.90      0.95        20\n","\n","    accuracy                           0.91      1000\n","   macro avg       0.92      0.91      0.91      1000\n","weighted avg       0.92      0.91      0.91      1000\n","\n","[[18  0  0 ...  0  0  0]\n"," [ 0 19  0 ...  0  0  0]\n"," [ 0  0 20 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 20  0  0]\n"," [ 0  0  0 ...  0 20  0]\n"," [ 2  0  0 ...  0  0 18]]\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","clf = KNeighborsClassifier(n_neighbors=3)\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"S47OtqOmJQqU"},"source":["## Classifying : DecisionTree"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46937,"status":"ok","timestamp":1712142015755,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"BoVlSohHJRLa","outputId":"94f03aeb-f9f7-4b15-9c18-c5d2a824414d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 10.0\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        20\n","           2       0.00      0.00      0.00        20\n","           3       0.95      0.90      0.92        20\n","           4       0.00      0.00      0.00        20\n","           5       0.02      1.00      0.05        20\n","           6       0.00      0.00      0.00        20\n","           7       0.00      0.00      0.00        20\n","           8       0.00      0.00      0.00        20\n","           9       0.00      0.00      0.00        20\n","          10       0.00      0.00      0.00        20\n","          11       0.00      0.00      0.00        20\n","          12       1.00      0.05      0.10        20\n","          13       0.00      0.00      0.00        20\n","          14       0.00      0.00      0.00        20\n","          15       1.00      0.75      0.86        20\n","          16       0.00      0.00      0.00        20\n","          17       0.00      0.00      0.00        20\n","          18       0.00      0.00      0.00        20\n","          19       0.00      0.00      0.00        20\n","          20       0.00      0.00      0.00        20\n","          21       0.25      0.80      0.38        20\n","          22       0.00      0.00      0.00        20\n","          23       0.00      0.00      0.00        20\n","          24       0.00      0.00      0.00        20\n","          25       0.00      0.00      0.00        20\n","          26       0.00      0.00      0.00        20\n","          27       0.00      0.00      0.00        20\n","          28       0.00      0.00      0.00        20\n","          29       0.00      0.00      0.00        20\n","          30       0.00      0.00      0.00        20\n","          31       0.00      0.00      0.00        20\n","          32       0.00      0.00      0.00        20\n","          33       0.00      0.00      0.00        20\n","          34       0.00      0.00      0.00        20\n","          35       0.00      0.00      0.00        20\n","          36       0.81      0.65      0.72        20\n","          37       0.00      0.00      0.00        20\n","          38       0.00      0.00      0.00        20\n","          39       0.00      0.00      0.00        20\n","          40       0.00      0.00      0.00        20\n","          41       0.00      0.00      0.00        20\n","          42       0.00      0.00      0.00        20\n","          43       0.00      0.00      0.00        20\n","          44       0.00      0.00      0.00        20\n","          45       0.00      0.00      0.00        20\n","          46       0.00      0.00      0.00        20\n","          47       0.00      0.00      0.00        20\n","          48       0.94      0.85      0.89        20\n","          49       0.00      0.00      0.00        20\n","          50       0.00      0.00      0.00        20\n","\n","    accuracy                           0.10      1000\n","   macro avg       0.10      0.10      0.08      1000\n","weighted avg       0.10      0.10      0.08      1000\n","\n","[[ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0 18 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 17  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]}],"source":["from sklearn import tree\n","\n","clf = tree.DecisionTreeClassifier(max_depth=5)\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"2G9YdhB7WIts"},"source":["## Classifying : AdaBoost"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1068236,"status":"ok","timestamp":1712143101575,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"5OPaz4h-ZWit","outputId":"5d3d240b-7171-4ff8-f20b-af67b053292d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:% 11.700000000000001\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        20\n","           2       0.00      0.00      0.00        20\n","           3       0.86      0.90      0.88        20\n","           4       0.00      0.00      0.00        20\n","           5       0.00      0.00      0.00        20\n","           6       0.00      0.00      0.00        20\n","           7       0.00      0.00      0.00        20\n","           8       0.00      0.00      0.00        20\n","           9       0.00      0.00      0.00        20\n","          10       0.00      0.00      0.00        20\n","          11       0.00      0.00      0.00        20\n","          12       0.00      0.00      0.00        20\n","          13       0.00      0.00      0.00        20\n","          14       0.00      0.00      0.00        20\n","          15       0.94      0.75      0.83        20\n","          16       0.00      0.00      0.00        20\n","          17       0.00      0.00      0.00        20\n","          18       0.00      0.00      0.00        20\n","          19       0.88      0.35      0.50        20\n","          20       0.00      0.00      0.00        20\n","          21       0.25      0.80      0.38        20\n","          22       0.00      0.00      0.00        20\n","          23       0.00      0.00      0.00        20\n","          24       0.24      0.60      0.34        20\n","          25       0.00      0.00      0.00        20\n","          26       0.00      0.00      0.00        20\n","          27       0.00      0.00      0.00        20\n","          28       0.00      0.00      0.00        20\n","          29       0.00      0.00      0.00        20\n","          30       0.00      0.00      0.00        20\n","          31       0.00      0.00      0.00        20\n","          32       0.00      0.00      0.00        20\n","          33       0.00      0.00      0.00        20\n","          34       0.00      0.00      0.00        20\n","          35       0.02      0.95      0.05        20\n","          36       0.72      0.65      0.68        20\n","          37       0.00      0.00      0.00        20\n","          38       0.00      0.00      0.00        20\n","          39       0.00      0.00      0.00        20\n","          40       0.00      0.00      0.00        20\n","          41       0.00      0.00      0.00        20\n","          42       0.00      0.00      0.00        20\n","          43       0.00      0.00      0.00        20\n","          44       0.00      0.00      0.00        20\n","          45       0.00      0.00      0.00        20\n","          46       0.00      0.00      0.00        20\n","          47       0.00      0.00      0.00        20\n","          48       0.81      0.85      0.83        20\n","          49       0.00      0.00      0.00        20\n","          50       0.00      0.00      0.00        20\n","\n","    accuracy                           0.12      1000\n","   macro avg       0.09      0.12      0.09      1000\n","weighted avg       0.09      0.12      0.09      1000\n","\n","[[ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0 18 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ... 17  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]}],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","estimator = tree.DecisionTreeClassifier(max_depth=1)\n","clf = AdaBoostClassifier(estimator=estimator, n_estimators=100, random_state=42)\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","report = classification_report(ytest, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"NqUZB56WkWlR"},"source":["## Classifying : XGBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":442023,"status":"ok","timestamp":1712143543592,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"S2l0eblLkWQ_","outputId":"c362d537-525b-4fc8-dadb-7133b38aa27f"},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","clf = XGBClassifier()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"20k0IhXEpswp"},"source":["## Classifying : CatBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":964},"executionInfo":{"elapsed":57170,"status":"error","timestamp":1712143627007,"user":{"displayName":"Amir Hossein","userId":"15147328249320673283"},"user_tz":-210},"id":"StFCKspjlriu","outputId":"e0e89202-d5d4-4c57-94ea-360ac45305a4"},"outputs":[],"source":["# !pip install catboost\n","\n","from catboost import CatBoostClassifier\n","\n","clf = CatBoostClassifier()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"R8zCMOcOqDyG"},"source":["## Classifying : Gradient Boost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Lrk7R4wmYN_"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)  # You can adjust the number of estimators and learning rate as needed\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"gPXXdibdqLML"},"source":["## Classifying : LightGBM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJ7bY35vlClk","outputId":"8fc54ac0-fdf8-4b80-db27-3e616c65c7c5"},"outputs":[],"source":["from lightgbm import LGBMClassifier\n","\n","clf = LGBMClassifier()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"EsZmVo5XqSiW"},"source":["## Classifying : LDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dx78FCnOnPUv","outputId":"467c5015-bf4c-4dab-fcca-79908bc717aa"},"outputs":[],"source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","clf = LinearDiscriminantAnalysis()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"xaK-eADnqXv5"},"source":["## Classifying : QDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2dYSncUjnuL7","outputId":"bd5e5cf2-ba78-4193-a8bf-fb6c865abbb9"},"outputs":[],"source":["from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","\n","clf = QuadraticDiscriminantAnalysis()\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]},{"cell_type":"markdown","metadata":{"id":"_kEBfpG-qjGn"},"source":["## Classifying : Bagging"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPKE4GdZoDSf","outputId":"7ee59b3a-5816-49b7-f002-a25c97f34e68"},"outputs":[],"source":["from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","estimator = DecisionTreeClassifier()\n","clf = BaggingClassifier(estimator, n_estimators=10, random_state=42)\n","clf.fit(xtrain, ytrain)\n","y_pred = clf.predict(xtest)\n","\n","accuracy = accuracy_score(ytest, y_pred)\n","print(f\"Accuracy:% {accuracy * 100}\")\n","\n","conf = confusion_matrix(ytest, y_pred)\n","print(conf)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}
