{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machines) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperplane and Margin\n",
    "> SVMs aim to find the optimal hyperplane that separates data points of different classes. In a 2D space, this hyperplane is a line, while in higher dimensions, it becomes a plane or a hyperplane.\n",
    "\n",
    "#### How It Works\n",
    ">The key idea is to **maximize** the **margin**, *which is the distance between the hyperplane and the nearest data points from each class.* These nearest points are called support vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear and Non-linear Classification\n",
    "- **Linear SVM**: If the data is linearly separable, SVM finds a straight line (or hyperplane) that separates the classes.\n",
    "- **Non-linear SVM**: For non-linearly separable data, SVM uses a technique called the **kernel trick** to transform the data into a higher-dimensional space where a linear separator can be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Functions\n",
    "- Linear Kernel: Suitable for linearly separable data.\n",
    "- Polynomial Kernel: Handles more complex relationships.\n",
    "- Radial Basis Function (RBF) Kernel: Effective for non-linear data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
